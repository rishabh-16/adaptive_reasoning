{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a3fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabhtiwari/.conda/envs/01_training/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input lengths: [2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-72B-Instruct\")\n",
    "\n",
    "def get_input_lengths(texts, tokenizer):\n",
    "    encoded = tokenizer.batch_encode_plus(texts)\n",
    "    input_lengths = [len(ids) for ids in encoded['input_ids']]\n",
    "    return input_lengths\n",
    "\n",
    "input_lengths = get_input_lengths(['level_results', 'hello', 'world'], tokenizer)\n",
    "print(f\"Input lengths: {input_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dba425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question IDs by difficulty level:\n",
      "Level 1: 43 questions\n",
      "  IDs: [14, 16, 18, 38, 58]...\n",
      "Level 2: 90 questions\n",
      "  IDs: [0, 4, 5, 13, 27]...\n",
      "Level 3: 105 questions\n",
      "  IDs: [2, 3, 6, 8, 10]...\n",
      "Level 4: 128 questions\n",
      "  IDs: [7, 17, 31, 32, 33]...\n",
      "Level 5: 134 questions\n",
      "  IDs: [1, 9, 11, 12, 15]...\n"
     ]
    }
   ],
   "source": [
    "math500_dataset_file = \"/home/rishabhtiwari/adaptive_reasoning/qwen3_math_evaluation/data/math500/test.jsonl\"\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Read the JSONL file and extract IDs by difficulty level\n",
    "level_to_ids = defaultdict(list)\n",
    "\n",
    "with open(math500_dataset_file, 'r') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        data = json.loads(line.strip())\n",
    "        # print(data.keys())\n",
    "        # raise Exception(\"Stop here\")\n",
    "        problem_id = idx # Handle different ID field names\n",
    "        level = data.get('level', 0)    # Handle different level field names\n",
    "        \n",
    "        if problem_id is not None and level is not None:\n",
    "            level_to_ids[level].append(problem_id)\n",
    "\n",
    "# Convert to regular dict and display summary\n",
    "level_to_ids = dict(level_to_ids)\n",
    "print(\"Question IDs by difficulty level:\")\n",
    "for level in sorted(level_to_ids.keys()):\n",
    "    print(f\"Level {level}: {len(level_to_ids[level])} questions\")\n",
    "    print(f\"  IDs: {level_to_ids[level][:5]}{'...' if len(level_to_ids[level]) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f682013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the result file and analyze the results\n",
    "\n",
    "def get_levelwise_results(result_file, level_to_ids, tokenizer, return_lengths=False):\n",
    "    results = []\n",
    "    with open(result_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            results.append(data)\n",
    "    level_to_results = defaultdict(list)\n",
    "    level_to_results_lengths = defaultdict(list)\n",
    "\n",
    "    for level in sorted(level_to_ids.keys()):\n",
    "        level_ids = level_to_ids[level]\n",
    "        level_results = []\n",
    "        level_results_lengths = []\n",
    "        for level_id in level_ids:\n",
    "            level_result = results[level_id]\n",
    "            level_results.append(level_result['score'])\n",
    "            if return_lengths:\n",
    "                output_lengths = get_input_lengths(level_result['code'], tokenizer)\n",
    "                level_results_lengths.append(output_lengths)\n",
    "        level_to_results[level] = level_results\n",
    "        level_to_results_lengths[level] = level_results_lengths\n",
    "    return level_to_results, level_to_results_lengths\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-72B-Instruct\")\n",
    "result_file =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/short_runs/qwen3-1676884_checkpoint416_max_tokens_per_call16000_thinking_budget-1/math500/test_qwen25-math-cot_-1_seed0_t0.7_top_k8_s0_e-1.jsonl\"\n",
    "\n",
    "level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids, tokenizer)\n",
    "# print(level_to_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189c816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.97, 2: 0.98, 3: 0.99, 4: 0.94, 5: 0.89}\n"
     ]
    }
   ],
   "source": [
    "from math import comb\n",
    "def get_levelwise_pass_at_1(level_to_results):\n",
    "    level_to_pass_at_1 = {}\n",
    "    for level, results in level_to_results.items():\n",
    "        level_to_pass_at_1[level] = round(np.mean(results), 8)\n",
    "    return level_to_pass_at_1\n",
    "\n",
    "def get_pass_at_k(results, k):\n",
    "    pass_at_k = []\n",
    "    for result in results:\n",
    "        c = np.sum(result)\n",
    "        n = len(result)\n",
    "        k = min(k, n)\n",
    "        if k > n - c:\n",
    "            pass_at_k.append(1.0)\n",
    "        else:\n",
    "            temp = 1.0 - comb(n-c, k)/comb(n, k)\n",
    "            pass_at_k.append(temp)\n",
    "    return pass_at_k\n",
    "\n",
    "def get_levelwise_pass_at_k(level_to_results, k):\n",
    "    level_to_pass_at_k = {}\n",
    "    for level, results in level_to_results.items():\n",
    "        level_to_pass_at_k[level] = round(np.mean(get_pass_at_k(results, k)), 2)\n",
    "    return level_to_pass_at_k\n",
    "\n",
    "def get_levelwise_pass_at_k_with_std(level_to_results, k):\n",
    "    level_to_pass_at_k = {}\n",
    "    level_to_std = {}\n",
    "    for level, results in level_to_results.items():\n",
    "        pass_at_k_values = get_pass_at_k(results, k)\n",
    "        level_to_pass_at_k[level] = round(np.mean(pass_at_k_values), 2)\n",
    "        level_to_std[level] = round(np.std(pass_at_k_values), 4)\n",
    "    return level_to_pass_at_k, level_to_std\n",
    "\n",
    "level_to_pass_at_1 = get_levelwise_pass_at_k(level_to_results, 2)\n",
    "print(level_to_pass_at_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5b6a6",
   "metadata": {},
   "source": [
    "# Math500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb49bab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "1676884 8\n",
      "{1: 0.98, 2: 0.98, 3: 1.0, 4: 0.96, 5: 0.92}\n",
      "1676884 12\n",
      "{1: 0.95, 2: 0.99, 3: 0.98, 4: 0.95, 5: 0.92}\n",
      "1676884 16\n",
      "{1: 0.97, 2: 0.99, 3: 0.96, 4: 0.96, 5: 0.89}\n",
      "1676884 32\n",
      "{1: 0.92, 2: 0.91, 3: 0.87, 4: 0.76, 5: 0.6}\n",
      "--------------------------------\n",
      "1677711 8\n",
      "{1: 0.98, 2: 0.98, 3: 0.99, 4: 0.96, 5: 0.92}\n",
      "1677711 12\n",
      "{1: 0.95, 2: 0.98, 3: 0.99, 4: 0.95, 5: 0.91}\n",
      "1677711 16\n",
      "{1: 0.98, 2: 0.99, 3: 0.99, 4: 0.95, 5: 0.91}\n",
      "1677711 32\n",
      "{1: 0.95, 2: 0.98, 3: 0.96, 4: 0.94, 5: 0.88}\n",
      "--------------------------------\n",
      "1677706 8\n",
      "{1: 0.98, 2: 0.97, 3: 1.0, 4: 0.96, 5: 0.92}\n",
      "1677706 12\n",
      "{1: 0.97, 2: 0.97, 3: 0.99, 4: 0.96, 5: 0.92}\n",
      "1677706 16\n",
      "{1: 0.98, 2: 0.98, 3: 1.0, 4: 0.96, 5: 0.92}\n",
      "1677706 32\n",
      "{1: 0.95, 2: 0.97, 3: 0.98, 4: 0.95, 5: 0.91}\n",
      "--------------------------------\n",
      "1677712 8\n",
      "{1: 0.99, 2: 0.97, 3: 1.0, 4: 0.96, 5: 0.9}\n",
      "1677712 12\n",
      "{1: 0.97, 2: 0.97, 3: 1.0, 4: 0.95, 5: 0.92}\n",
      "1677712 16\n",
      "{1: 0.97, 2: 0.98, 3: 1.0, 4: 0.95, 5: 0.92}\n",
      "1677712 32\n",
      "{1: 0.94, 2: 0.98, 3: 1.0, 4: 0.95, 5: 0.92}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1676884', '1677711', '1677706', '1677712']\n",
    "top_ks = [8, 12, 16, 32]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/math500/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "for experiment_id in experiment_ids:\n",
    "    print(\"--------------------------------\")\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results, 4)\n",
    "            print(level_to_pass_at_k)\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "699dbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "trained for  4\n",
      "1695599 4\n",
      "{0: 0.96}\n",
      "1695599 6\n",
      "{0: 0.95}\n",
      "1695599 8\n",
      "{0: 0.95}\n",
      "1695599 10\n",
      "Error in 1695599 10\n",
      "1695599 12\n",
      "{0: 0.88}\n",
      "1695599 14\n",
      "{0: 0.83}\n",
      "1695599 16\n",
      "Error in 1695599 16\n",
      "--------------------------------\n",
      "trained for  6\n",
      "1695805 4\n",
      "Error in 1695805 4\n",
      "1695805 6\n",
      "{0: 0.96}\n",
      "1695805 8\n",
      "{0: 0.96}\n",
      "1695805 10\n",
      "{0: 0.96}\n",
      "1695805 12\n",
      "{0: 0.95}\n",
      "1695805 14\n",
      "Error in 1695805 14\n",
      "1695805 16\n",
      "{0: 0.92}\n",
      "--------------------------------\n",
      "trained for  8\n",
      "1676884 4\n",
      "{0: 0.94}\n",
      "1676884 6\n",
      "{0: 0.96}\n",
      "1676884 8\n",
      "{0: 0.96}\n",
      "1676884 10\n",
      "{0: 0.96}\n",
      "1676884 12\n",
      "{0: 0.95}\n",
      "1676884 14\n",
      "{0: 0.95}\n",
      "1676884 16\n",
      "{0: 0.95}\n",
      "--------------------------------\n",
      "trained for  10\n",
      "1695806 4\n",
      "Error in 1695806 4\n",
      "1695806 6\n",
      "{0: 0.96}\n",
      "1695806 8\n",
      "{0: 0.95}\n",
      "1695806 10\n",
      "{0: 0.96}\n",
      "1695806 12\n",
      "{0: 0.96}\n",
      "1695806 14\n",
      "Error in 1695806 14\n",
      "1695806 16\n",
      "{0: 0.95}\n",
      "--------------------------------\n",
      "trained for  12\n",
      "1677711 4\n",
      "{0: 0.91}\n",
      "1677711 6\n",
      "{0: 0.96}\n",
      "1677711 8\n",
      "{0: 0.96}\n",
      "1677711 10\n",
      "{0: 0.96}\n",
      "1677711 12\n",
      "{0: 0.96}\n",
      "1677711 14\n",
      "{0: 0.96}\n",
      "1677711 16\n",
      "{0: 0.96}\n",
      "--------------------------------\n",
      "trained for  14\n",
      "1695807 4\n",
      "{0: 0.9}\n",
      "1695807 6\n",
      "Error in 1695807 6\n",
      "1695807 8\n",
      "Error in 1695807 8\n",
      "1695807 10\n",
      "{0: 0.96}\n",
      "1695807 12\n",
      "Error in 1695807 12\n",
      "1695807 14\n",
      "{0: 0.96}\n",
      "1695807 16\n",
      "{0: 0.96}\n",
      "--------------------------------\n",
      "trained for  16\n",
      "1677706 4\n",
      "{0: 0.87}\n",
      "1677706 6\n",
      "{0: 0.95}\n",
      "1677706 8\n",
      "{0: 0.96}\n",
      "1677706 10\n",
      "Error in 1677706 10\n",
      "1677706 12\n",
      "{0: 0.96}\n",
      "1677706 14\n",
      "{0: 0.96}\n",
      "1677706 16\n",
      "{0: 0.96}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1695599', '1695805', '1676884', '1695806','1677711','1695807','1677706']\n",
    "top_ks = [4, 6, 8, 10, 12, 14, 16]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/math500/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "for idx, experiment_id in enumerate(experiment_ids):\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"trained for \", top_ks[idx])\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results, 4)\n",
    "            print(level_to_pass_at_k)\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e73b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "1709227 4\n",
      "{1: 0.97, 2: 0.99, 3: 0.99, 4: 0.97, 5: 0.91}\n",
      "1709227 6\n",
      "{1: 0.97, 2: 0.99, 3: 0.99, 4: 0.97, 5: 0.91}\n",
      "1709227 8\n",
      "{1: 0.95, 2: 0.98, 3: 1.0, 4: 0.96, 5: 0.91}\n",
      "1709227 12\n",
      "{1: 0.97, 2: 0.98, 3: 0.99, 4: 0.97, 5: 0.92}\n",
      "1709227 14\n",
      "{1: 0.98, 2: 0.98, 3: 1.0, 4: 0.98, 5: 0.92}\n",
      "1709227 16\n",
      "{1: 0.98, 2: 0.97, 3: 0.99, 4: 0.96, 5: 0.92}\n",
      "1709227 32\n",
      "{1: 0.98, 2: 0.99, 3: 0.99, 4: 0.96, 5: 0.93}\n",
      "--------------------------------\n",
      "1709239 4\n",
      "Error in 1709239 4\n",
      "1709239 6\n",
      "{1: 0.97, 2: 0.98, 3: 1.0, 4: 0.97, 5: 0.92}\n",
      "1709239 8\n",
      "{1: 0.97, 2: 0.98, 3: 1.0, 4: 0.97, 5: 0.92}\n",
      "1709239 12\n",
      "{1: 0.97, 2: 0.98, 3: 0.99, 4: 0.96, 5: 0.92}\n",
      "1709239 14\n",
      "{1: 0.98, 2: 0.99, 3: 1.0, 4: 0.97, 5: 0.91}\n",
      "1709239 16\n",
      "Error in 1709239 16\n",
      "1709239 32\n",
      "{1: 0.98, 2: 0.98, 3: 0.99, 4: 0.97, 5: 0.93}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1709227', '1709239']\n",
    "top_ks = [4, 6, 8, 12, 14, 16, 32]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/math500/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "for experiment_id in experiment_ids:\n",
    "    print(\"--------------------------------\")\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results, 4)\n",
    "            print(level_to_pass_at_k)\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "081a2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "1717456 4\n",
      "Error in 1717456 4\n",
      "1717456 6\n",
      "Error in 1717456 6\n",
      "1717456 8\n",
      "{1: 0.98, 2: 0.98, 3: 0.99, 4: 0.97, 5: 0.92}\n",
      "1717456 12\n",
      "{1: 0.99, 2: 0.99, 3: 0.99, 4: 0.97, 5: 0.93}\n",
      "1717456 14\n",
      "{1: 0.97, 2: 0.99, 3: 0.99, 4: 0.97, 5: 0.91}\n",
      "1717456 16\n",
      "{1: 0.98, 2: 0.99, 3: 0.97, 4: 0.96, 5: 0.91}\n",
      "1717456 32\n",
      "Error in 1717456 32\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1717456']\n",
    "top_ks = [4, 6, 8, 12, 14, 16, 32]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/math500/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "for experiment_id in experiment_ids:\n",
    "    print(\"--------------------------------\")\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results, 4)\n",
    "            print(level_to_pass_at_k)\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7e99f",
   "metadata": {},
   "source": [
    "## AIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52489528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question IDs by difficulty level:\n",
      "Level 0: 30 questions\n",
      "  IDs: [0, 1, 2, 3, 4]...\n"
     ]
    }
   ],
   "source": [
    "aime_dataset_file = \"/home/rishabhtiwari/adaptive_reasoning/qwen3_math_evaluation/data/aime25/test.jsonl\"\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Read the JSONL file and extract IDs by difficulty level\n",
    "level_to_ids_aime = defaultdict(list)\n",
    "\n",
    "with open(aime_dataset_file, 'r') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        data = json.loads(line.strip())\n",
    "        # print(data.keys())\n",
    "        # raise Exception(\"Stop here\")\n",
    "        problem_id = idx # Handle different ID field names\n",
    "        level = data.get('level', data.get('i', 0))    # Handle different level field names\n",
    "        \n",
    "        if problem_id is not None and level is not None:\n",
    "            level_to_ids_aime[level].append(problem_id)\n",
    "\n",
    "# Convert to regular dict and display summary\n",
    "level_to_ids_aime = dict(level_to_ids_aime)\n",
    "print(\"Question IDs by difficulty level:\")\n",
    "for level in sorted(level_to_ids_aime.keys()):\n",
    "    print(f\"Level {level}: {len(level_to_ids_aime[level])} questions\")\n",
    "    print(f\"  IDs: {level_to_ids_aime[level][:5]}{'...' if len(level_to_ids_aime[level]) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0dfc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "1676884 8\n",
      "{0: 0.39}\n",
      "1676884 12\n",
      "{0: 0.33}\n",
      "1676884 16\n",
      "{0: 0.32}\n",
      "1676884 32\n",
      "{0: 0.09}\n",
      "--------------------------------\n",
      "1677711 8\n",
      "{0: 0.41}\n",
      "1677711 12\n",
      "{0: 0.39}\n",
      "1677711 16\n",
      "{0: 0.35}\n",
      "1677711 32\n",
      "{0: 0.27}\n",
      "--------------------------------\n",
      "1677706 8\n",
      "{0: 0.37}\n",
      "1677706 12\n",
      "{0: 0.41}\n",
      "1677706 16\n",
      "{0: 0.4}\n",
      "1677706 32\n",
      "{0: 0.34}\n",
      "--------------------------------\n",
      "1677712 8\n",
      "{0: 0.36}\n",
      "1677712 12\n",
      "{0: 0.41}\n",
      "1677712 16\n",
      "{0: 0.4}\n",
      "1677712 32\n",
      "{0: 0.4}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1676884', '1677711', '1677706', '1677712']\n",
    "top_ks = [8, 12, 16, 32]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/aime25/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "\n",
    "for experiment_id in experiment_ids:\n",
    "    print(\"--------------------------------\")\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids_aime, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results, 1)\n",
    "            print(level_to_pass_at_k)\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a08483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "trained for  4\n",
      "1695599 4\n",
      "{0: 0.35}\n",
      "1695599 6\n",
      "{0: 0.34}\n",
      "1695599 8\n",
      "{0: 0.28}\n",
      "1695599 10\n",
      "{0: 0.18}\n",
      "1695599 12\n",
      "{0: 0.12}\n",
      "1695599 14\n",
      "{0: 0.1}\n",
      "1695599 16\n",
      "{0: 0.04}\n",
      "--------------------------------\n",
      "trained for  6\n",
      "1695805 4\n",
      "Error in 1695805 4\n",
      "1695805 6\n",
      "{0: 0.35}\n",
      "1695805 8\n",
      "{0: 0.35}\n",
      "1695805 10\n",
      "{0: 0.36}\n",
      "1695805 12\n",
      "{0: 0.29}\n",
      "1695805 14\n",
      "{0: 0.24}\n",
      "1695805 16\n",
      "{0: 0.2}\n",
      "--------------------------------\n",
      "trained for  8\n",
      "1676884 4\n",
      "Error in 1676884 4\n",
      "1676884 6\n",
      "Error in 1676884 6\n",
      "1676884 8\n",
      "{0: 0.39}\n",
      "1676884 10\n",
      "{0: 0.38}\n",
      "1676884 12\n",
      "{0: 0.33}\n",
      "1676884 14\n",
      "{0: 0.3}\n",
      "1676884 16\n",
      "{0: 0.32}\n",
      "--------------------------------\n",
      "trained for  10\n",
      "1695806 4\n",
      "{0: 0.22}\n",
      "1695806 6\n",
      "{0: 0.36}\n",
      "1695806 8\n",
      "{0: 0.35}\n",
      "1695806 10\n",
      "Error in 1695806 10\n",
      "1695806 12\n",
      "{0: 0.36}\n",
      "1695806 14\n",
      "{0: 0.38}\n",
      "1695806 16\n",
      "{0: 0.36}\n",
      "--------------------------------\n",
      "trained for  12\n",
      "1677711 4\n",
      "{0: 0.25}\n",
      "1677711 6\n",
      "Error in 1677711 6\n",
      "1677711 8\n",
      "{0: 0.41}\n",
      "1677711 10\n",
      "Error in 1677711 10\n",
      "1677711 12\n",
      "{0: 0.39}\n",
      "1677711 14\n",
      "{0: 0.37}\n",
      "1677711 16\n",
      "{0: 0.35}\n",
      "--------------------------------\n",
      "trained for  14\n",
      "1695807 4\n",
      "Error in 1695807 4\n",
      "1695807 6\n",
      "Error in 1695807 6\n",
      "1695807 8\n",
      "{0: 0.38}\n",
      "1695807 10\n",
      "{0: 0.42}\n",
      "1695807 12\n",
      "{0: 0.39}\n",
      "1695807 14\n",
      "{0: 0.4}\n",
      "1695807 16\n",
      "{0: 0.4}\n",
      "--------------------------------\n",
      "trained for  16\n",
      "1677706 4\n",
      "Error in 1677706 4\n",
      "1677706 6\n",
      "{0: 0.36}\n",
      "1677706 8\n",
      "{0: 0.37}\n",
      "1677706 10\n",
      "{0: 0.38}\n",
      "1677706 12\n",
      "{0: 0.41}\n",
      "1677706 14\n",
      "{0: 0.41}\n",
      "1677706 16\n",
      "{0: 0.4}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1695599', '1695805', '1676884', '1695806','1677711','1695807','1677706']\n",
    "top_ks = [4, 6, 8, 10, 12, 14, 16]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/aime25/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "\n",
    "for idx, experiment_id in enumerate(experiment_ids):\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"trained for \", top_ks[idx])\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids_aime, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results, 1)\n",
    "            print(level_to_pass_at_k)\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "559b97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "1709227 4\n",
      "Mean: {0: 0.37}\n",
      "1709227 6\n",
      "Mean: {0: 0.41}\n",
      "1709227 8\n",
      "Mean: {0: 0.41}\n",
      "1709227 12\n",
      "Mean: {0: 0.45}\n",
      "1709227 14\n",
      "Mean: {0: 0.48}\n",
      "1709227 16\n",
      "Mean: {0: 0.4}\n",
      "1709227 32\n",
      "Mean: {0: 0.46}\n",
      "--------------------------------\n",
      "1709239 4\n",
      "Mean: {0: 0.38}\n",
      "1709239 6\n",
      "Mean: {0: 0.42}\n",
      "1709239 8\n",
      "Mean: {0: 0.4}\n",
      "1709239 12\n",
      "Mean: {0: 0.41}\n",
      "1709239 14\n",
      "Mean: {0: 0.46}\n",
      "1709239 16\n",
      "Mean: {0: 0.41}\n",
      "1709239 32\n",
      "Mean: {0: 0.42}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1709227', '1709239']\n",
    "top_ks = [4, 6, 8, 12, 14, 16, 32]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/aime25/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "\n",
    "for idx, experiment_id in enumerate(experiment_ids):\n",
    "    print(\"--------------------------------\")\n",
    "    # print(\"trained for \", top_ks[idx])\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids_aime, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results, 1)\n",
    "            print(f\"Mean: {level_to_pass_at_k}\")\n",
    "            # print(f\"Std:  {level_to_std}\")\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bd03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "1717456 4\n",
      "Mean: {0: 0.3}\n",
      "1717456 6\n",
      "Mean: {0: 0.4}\n",
      "1717456 8\n",
      "Mean: {0: 0.43}\n",
      "1717456 12\n",
      "Mean: {0: 0.45}\n",
      "1717456 14\n",
      "Mean: {0: 0.39}\n",
      "1717456 16\n",
      "Mean: {0: 0.38}\n",
      "1717456 32\n",
      "Mean: {0: 0.18}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1717456']\n",
    "top_ks = [4, 6, 8, 12, 14, 16, 32]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/aime25/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "\n",
    "for idx, experiment_id in enumerate(experiment_ids):\n",
    "    print(\"--------------------------------\")\n",
    "    # print(\"trained for \", top_ks[idx])\n",
    "    for top_k in top_ks:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids_aime, tokenizer)\n",
    "            level_to_pass_at_k = get_levelwise_pass_at_k(level_to_results,1)\n",
    "            print(f\"Mean: {level_to_pass_at_k}\")\n",
    "            # print(f\"Std:  {level_to_std}\")\n",
    "        except:\n",
    "            print(f\"Error in {experiment_id} {top_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d7ef3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "1676884 8\n",
      "{0: 0.57}\n",
      "--------------------------------\n",
      "1677711 8\n",
      "1677711 12\n",
      "{0: 0.51}\n",
      "--------------------------------\n",
      "1677706 8\n",
      "1677706 12\n",
      "1677706 16\n",
      "{0: 0.54}\n",
      "--------------------------------\n",
      "1677712 8\n",
      "1677712 12\n",
      "1677712 16\n",
      "1677712 32\n",
      "{0: 0.6}\n"
     ]
    }
   ],
   "source": [
    "result_id = 'short_runs'\n",
    "experiment_ids = ['1676884', '1677711', '1677706', '1677712']\n",
    "top_ks = [8, 12, 16, 32]\n",
    "result_file_format =\"/home/rishabhtiwari/adaptive_reasoning/experiments/03_evaluation/{result_id}/qwen3-{experiment_id}_checkpoint416_max_tokens_per_call16000_thinking_budget-1/aime25/test_qwen25-math-cot_-1_seed0_t0.7_top_k{top_k}_s0_e-1.jsonl\"\n",
    "\n",
    "\n",
    "for idx, experiment_id in enumerate(experiment_ids):\n",
    "    print(\"--------------------------------\")\n",
    "    overall_level_to_results = {}\n",
    "    for top_k in top_ks[:idx+1]:\n",
    "        print(experiment_id, top_k)\n",
    "        try:\n",
    "            result_file = result_file_format.format(result_id=result_id, experiment_id=experiment_id, top_k=top_k)\n",
    "            level_to_results, level_to_results_lengths = get_levelwise_results(result_file, level_to_ids_aime, tokenizer)\n",
    "            \n",
    "            # Combine results across different top_k values for each level\n",
    "            for level, results in level_to_results.items():\n",
    "                if level not in overall_level_to_results:\n",
    "                    combined_results = []\n",
    "                    for i in range(len(results)):\n",
    "                        combined_results.append(results[i][:8//(idx+1)])\n",
    "                else:\n",
    "                    combined_results = overall_level_to_results[level]\n",
    "                    for i in range(len(results)):\n",
    "                        combined_results[i] += results[i][:8//(idx+1)]\n",
    "                overall_level_to_results[level] = combined_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {experiment_id} {top_k}: {e}\")\n",
    "    \n",
    "    # Calculate pass@k for the combined results\n",
    "    level_to_pass_at_k = get_levelwise_pass_at_k(overall_level_to_results, 4)\n",
    "    print(level_to_pass_at_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "523a81d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overall_level_to_results[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cc3b40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_to_pass_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0255939e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(level_to_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d197db3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb(8,8)/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ad41730",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "results[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04f2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
