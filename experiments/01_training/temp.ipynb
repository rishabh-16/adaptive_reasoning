{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28f90fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabhtiwari/.conda/envs/01_training/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ '<think>' token found with ID: 151667\n",
      "\n",
      "Think-related tokens found:\n",
      "  'Ġthink': 1744\n",
      "  'Ġthinking': 7274\n",
      "  'Ġthinks': 15482\n",
      "  'ĠThink': 21149\n",
      "  'think': 26865\n",
      "  'Think': 38687\n",
      "  'ĠThinking': 52289\n",
      "  'Ġthinkers': 68022\n",
      "  'Ġrethink': 75655\n",
      "  'thinking': 82260\n",
      "  'thinkable': 90103\n",
      "  'ĠTHINK': 92119\n",
      "  'Thinking': 93945\n",
      "  'Ġunthinkable': 95503\n",
      "  'Ġthinker': 97536\n",
      "  '-thinking': 98951\n",
      "  '<think>': 151667\n",
      "  '</think>': 151668\n",
      "\n",
      "Vocabulary size: 151669\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer for the Qwen model\n",
    "model_name = \"Qwen/Qwen3-30B-A3B-Base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Check if <think> token exists in the tokenizer\n",
    "think_token = \"<think>\"\n",
    "if think_token in tokenizer.get_vocab():\n",
    "    token_id = tokenizer.get_vocab()[think_token]\n",
    "    print(f\"✅ '{think_token}' token found with ID: {token_id}\")\n",
    "else:\n",
    "    print(f\"❌ '{think_token}' token not found in tokenizer vocabulary\")\n",
    "\n",
    "# Also check the reverse - what tokens contain \"think\"\n",
    "think_related_tokens = {token: token_id for token, token_id in tokenizer.get_vocab().items() if \"think\" in token.lower()}\n",
    "if think_related_tokens:\n",
    "    print(f\"\\nThink-related tokens found:\")\n",
    "    for token, token_id in sorted(think_related_tokens.items(), key=lambda x: x[1]):\n",
    "        print(f\"  '{token}': {token_id}\")\n",
    "else:\n",
    "    print(\"\\nNo think-related tokens found in vocabulary\")\n",
    "\n",
    "# Check vocabulary size\n",
    "print(f\"\\nVocabulary size: {len(tokenizer.get_vocab())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f7eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython environment detected - magic commands should work\n"
     ]
    }
   ],
   "source": [
    "# First, let's make sure IPython magic commands are available\n",
    "from IPython import get_ipython\n",
    "if get_ipython() is not None:\n",
    "    # Enable IPython magic commands\n",
    "    print(\"IPython environment detected - magic commands should work\")\n",
    "else:\n",
    "    print(\"Not in IPython environment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4aef13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (this may take a while for first download)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 16/16 [00:07<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Model device: cpu\n",
      "<|im_start|>system\n",
      "Please reason step by step, and put your final answer within \\boxed{{}}<|im_end|>\n",
      "<|im_start|>user\n",
      "A train travels 240 miles in 3 hours. If it maintains the same speed, how long will it take to travel 400 miles?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Input question: A train travels 240 miles in 3 hours. If it maintains the same speed, how long will it take to travel 400 miles?\n",
      "\n",
      "Generating response...\n",
      "forward top_k: 8, iteration: 100\n",
      "forward top_k: 12, iteration: 101\n",
      "\n",
      "Model response:\n",
      "To solve this problem, we can use the formula: distance = speed x time. We know that the train travels 240 miles in 3 hours, so we can use this information to find the speed of the train. \n",
      "\n",
      "Speed = distance / time\n",
      "Speed = 240 miles / 3 hours\n",
      "Speed = 80 miles per hour\n",
      "\n",
      "Now that we know the speed of the train, we can use it to find out how long it will take to travel 400 miles. \n",
      "\n",
      "Time = distance / speed\n",
      "Time = 400 miles / 80 miles per hour\n",
      "Time = 5 hours\n",
      "\n",
      "So, it will take the train 5 hours to travel 400 miles if it maintains the same speed.\n",
      "\n",
      "\\boxed{{5 hours}}\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{{}}擞\n",
      "\n",
      "Assistant: A train travels 240 miles in 3 hours. If it maintains the same speed, how long will it take to travel 400 miles?擞\n",
      "\n",
      "To solve this problem, we can use the formula: distance = speed x time. We know that the train travels 240 miles in 3 hours, so we can use this information to find the speed of the train. \n",
      "\n",
      "Speed = distance / time\n",
      "Speed = 240 miles / 3 hours\n",
      "Speed = 80 miles per hour\n",
      "\n",
      "Now that we know the speed of the train, we can use it to find out how long it will take to travel 400 miles. \n",
      "\n",
      "Time = distance / speed\n",
      "Time = 400 miles / 80 miles per hour\n",
      "Time = 5 hours\n",
      "\n",
      "So, it will take the train 5 hours to travel 400 miles if it maintains the same speed.\n",
      "\n",
      "\\boxed{{5 hours}}\n"
     ]
    }
   ],
   "source": [
    "# %%writefile test_model.py\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Note: model_name and tokenizer should be defined in a previous cell\n",
    "model_name = \"/home/rishabhtiwari/hf_cache/Qwen--Qwen3-30B-A3B-Base\"\n",
    "\n",
    "# Set cache directory\n",
    "cache_dir = \"/home/rishabhtiwari/hf_cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# Download and load the model\n",
    "print(\"Loading model (this may take a while for first download)...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Sample math question\n",
    "math_question = \"\"\"A train travels 240 miles in 3 hours. If it maintains the same speed, how long will it take to travel 400 miles?\"\"\"\n",
    "\n",
    "# You'll need to import tokenizer and define it properly in your main script\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Prepare the input\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Please reason step by step, and put your final answer within \\\\boxed{{}}.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": math_question\n",
    "    }\n",
    "]\n",
    "\n",
    "# Tokenize the input\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(input_text)\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "print(f\"\\nInput question: {math_question}\")\n",
    "print(f\"\\nGenerating response...\")\n",
    "\n",
    "# Generate response\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the response \n",
    "response = tokenizer.decode(output[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "print(f\"\\nModel response:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28286e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response:\n",
      "Let's solve this step by step.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 1: Find the speed of the train**\n",
      "\n",
      "We know that:\n",
      "\n",
      "- Distance = 240 miles  \n",
      "- Time = 3 hours  \n",
      "\n",
      "Speed is calculated using the formula:\n",
      "\n",
      "$$\n",
      "\\text{Speed} = \\frac{\\text{Distance}}{\\text{Time}}\n",
      "$$\n",
      "\n",
      "$$\n",
      "\\text{Speed} = \\frac{240 \\text{ miles}}{3 \\text{ hours}} = 80 \\text{ miles per hour}\n",
      "$$\n",
      "\n",
      "So, the train is traveling at **80 mph**.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: Use the speed to find time for 400 miles**\n",
      "\n",
      "Now, we want to find how long it will take to travel **400 miles** at the same speed (80 mph).\n",
      "\n",
      "Use the formula:\n",
      "\n",
      "$$\n",
      "\\text{Time} = \\frac{\\text{Distance}}{\\text{Speed}}\n",
      "$$\n",
      "\n",
      "$$\n",
      "\\text{Time} = \\frac{400 \\text{ miles}}{80 \\text{ mph}} = 5 \\text{ hours}\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ **Final Answer:**\n",
      "\n",
      "$$\n",
      "\\boxed{5} \\text{ hours}\n",
      "$$\n",
      "\n",
      "It will take **5 hours** to travel 400 miles at the same speed.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(output[0][input_ids.shape[1]:], skip_special_tokens=False)\n",
    "print(f\"\\nModel response:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b1535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
